<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Predicting Traffic Flow | Shyngys Narseyit</title>
    <!-- Google Colors / Material UI styles -->
    <link rel="stylesheet" href="style.css">
    <!-- Lucide Icons -->
    <script src="https://unpkg.com/lucide@latest"></script>
    <!-- Highlight.js for Code Snippets -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
</head>

<body>

    <nav class="g-nav">
        <div class="brand">
            <div class="hero-g-logo" style="margin:0; gap:2px;">
                <div class="circle c-blue" style="width:10px; height:10px;"></div>
                <div class="circle c-red" style="width:10px; height:10px;"></div>
                <div class="circle c-yellow" style="width:10px; height:10px;"></div>
                <div class="circle c-green" style="width:10px; height:10px;"></div>
            </div>
            <span>SN</span> Portfolio
        </div>
        <div class="nav-links">
            <a href="#ideation">Ideation</a>
            <a href="#problem">Problem</a>
            <a href="#methodology">Methodology</a>
            <a href="#showdown">Showdown</a>
            <a href="#architecture">Architecture</a>
        </div>
        <a href="https://github.com/shyngysdesigner/1dCNNandGRU" class="btn-primary" target="_blank">
            <i data-lucide="github"></i> GitHub
        </a>
    </nav>

    <main>
        <!-- 1. Hero -->
        <section class="hero reveal active" id="hero">
            <div class="hero-g-logo">
                <div class="circle c-blue"></div>
                <div class="circle c-red"></div>
                <div class="circle c-yellow"></div>
                <div class="circle c-green"></div>
            </div>
            <h1>Predicting the Unpredictable</h1>
            <p class="hero-p">A powerful spatial-temporal Hybrid CNN-GRU model implemented in PyTorch for precise,
                dynamic traffic flow prediction.</p>
            <div style="display: flex; gap: 16px; justify-content: center;">
                <a href="#architecture" class="btn-primary">View Architecture</a>
                <a href="#results" class="btn-secondary">View Results</a>
            </div>
        </section>

        <!-- 2. Ideation / How I thought before starting -->
        <section class="g-card reveal" id="ideation">
            <div class="section-header">
                <h2>1. Initial Thoughts & Planning</h2>
                <p>How I approached the complexity of traffic prediction before writing a single line of code.</p>
            </div>
            <div class="grid-2">
                <div>
                    <div class="icon-box ib-blue"><i data-lucide="brain"></i></div>
                    <h3>Mental Sandbox</h3>
                    <p style="color: var(--text-sec); margin-top: 8px;">
                        Before jumping into deep learning, I realized traffic isn't just a basic time-series. It's a
                        living grid. I sketched out out how a traffic jam on Road A directly impacts Road B a few
                        minutes later. I knew standard models would fail because they only look at one dimension at a
                        time. I needed a model that could "see" the map geometrically and "remember" the timeline
                        chronologically.
                    </p>
                </div>
                <div>
                    <div class="icon-box ib-red"><i data-lucide="merge"></i></div>
                    <h3>The Synthesis</h3>
                    <p style="color: var(--text-sec); margin-top: 8px;">
                        I decided to fuse two distinct architectures. The idea: Let a <strong>Convolutional Neural
                            Network (1D CNN)</strong> act as the "eyes," scanning across all 325 sensors simultaneously
                        to understand local spatial bounds. Then, pass that compressed understanding to a <strong>Gated
                            Recurrent Unit (GRU)</strong>, which acts as the "memory loop" to project traffic speeds
                        securely into the future hour.
                    </p>
                </div>
            </div>
        </section>

        <!-- 3. The Problem & Data Engineering -->
        <section class="g-card reveal" id="problem">
            <div class="section-header">
                <h2>2. The Problem & Data Engineering</h2>
                <p>Injecting physics and continuity into numerical data.</p>
            </div>
            <div style="margin-bottom: 24px;">
                <p style="color: var(--text-sec);">
                    Traffic patterns are circular (every Monday behaves somewhat like the last Monday, every 5 PM is
                    somewhat similar). I converted abrupt numerical leaps into smooth mathematical waves by creating
                    <strong>cyclical sine and cosine embeddings</strong> inside the <code
                        style="background:none;">load_and_enrich_data</code> function.
                </p>
            </div>
            <div class="code-header">traffic_prediction.py</div>
            <pre class="hljs-container"><code class="language-python"># Calculate continuous cyclical features
hour = df.index.hour + df.index.minute / 60.0
day_of_week = df.index.dayofweek

# Sine & Cosine Cyclical Transformations
time_features = pd.DataFrame(index=df.index)
time_features['sin_hour'] = np.sin(2 * np.pi * hour / 24.0)
time_features['cos_hour'] = np.cos(2 * np.pi * hour / 24.0)
time_features['sin_day'] = np.sin(2 * np.pi * day_of_week / 7.0)
time_features['cos_day'] = np.cos(2 * np.pi * day_of_week / 7.0)

# Concatenate temporal features with spatial sensor data
df = pd.concat([df, time_features], axis=1)</code></pre>
        </section>

        <!-- 4. Methodology & Design Choices -->
        <section class="g-card reveal" id="methodology">
            <div class="section-header">
                <h2>3. Methodology & Design Choices</h2>
                <p>Data preparation pipelines and hyperparameter reasoning.</p>
            </div>

            <div class="grid-2">
                <div>
                    <h3 style="margin-bottom: 8px;">Data Scaling & Cleaning</h3>
                    <p style="color: var(--text-sec); font-size: 14px;">
                        The raw PEMS-BAY dataset holds over 52,000 timesteps across 325 sensors. I replaced broken
                        <code>0.0</code> entries with <code>NaN</code> and applied <strong>linear
                            interpolation</strong>. Finally, utilizing Scikit-learn's <code>MinMaxScaler</code>, I
                        constrained the sensor attributes so gradients wouldn't explode during training.
                    </p>
                </div>
                <div>
                    <h3 style="margin-bottom: 8px;">Hyperparameters</h3>
                    <ul style="color: var(--text-sec); font-size: 14px; padding-left: 18px;">
                        <li><strong>Kernel = 3:</strong> The optimal bounding box for Conv1d to catch localized
                            intersection choke points.</li>
                        <li><strong>Sequence = 12:</strong> 12 x 5-minute ticks = 1 Hour. This provides sufficient
                            historical context without diluting attention.</li>
                        <li><strong>Epochs = 30:</strong> Combined with <code>ReduceLROnPlateau</code> constraints to
                            dynamically stop once validation flattens.</li>
                    </ul>
                </div>
            </div>

            <div style="margin-top: 32px;">
                <h3 style="margin-bottom: 8px;">Sliding Window Technique</h3>
                <p style="color: var(--text-sec); font-size: 14px;">
                    Neural nets expect structured blocks. I used a sliding window loop algorithm to step through the
                    massive timeline, creating identical overlapping chunks. By isolating 12 historical timestamps
                    <code>X</code> to predict the 13th target <code>y</code>, we synthesize a robust dataset of
                    standalone events.
                </p>

                <!-- Sliding Window Animation -->
                <div class="sw-anim-box">
                    <div class="sw-row">
                        <div class="sw-cell">T1</div>
                        <div class="sw-cell">T2</div>
                        <div class="sw-cell">T3</div>
                        <div class="sw-cell">T4</div>
                        <div class="sw-cell">T5</div>
                        <div class="sw-cell">T6</div>
                        <div class="sw-cell">T7</div>
                        <div class="sw-cell">T8</div>
                        <div class="sw-cell">T9</div>

                        <div class="sw-x-box"><span class="label-xy" style="color: var(--g-blue);">Inputs (X)</span>
                        </div>
                        <div class="sw-y-box"><span class="label-xy" style="color: var(--g-green);">Target (y)</span>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- 5. Architecture Showdown -->
        <section class="g-card reveal" id="showdown">
            <div class="section-header" style="text-align: center;">
                <h2>4. The Architecture Showdown</h2>
                <p>Comparing deep learning paradigms.</p>
            </div>

            <div class="grid-3">
                <div class="g-card showdown-card" style="box-shadow:none; border:1px solid #eee;">
                    <div class="icon-box ib-yellow" style="margin: 0 auto 16px;"><i data-lucide="image"></i></div>
                    <h4>Pure CNNs</h4>
                    <p style="color: var(--text-sec); font-size: 14px; margin-top: 8px;">Masters of spatial mapping
                        (images), but completely amnesic regarding sequence steps over time.</p>
                </div>
                <div class="g-card showdown-card" style="box-shadow:none; border:1px solid #eee;">
                    <div class="icon-box ib-red" style="margin: 0 auto 16px;"><i data-lucide="history"></i></div>
                    <h4>Pure LSTMs</h4>
                    <p style="color: var(--text-sec); font-size: 14px; margin-top: 8px;">Powerful sequentially, but
                        utterly blind to the geographical distance mapping between specific traffic gates.</p>
                </div>
                <div class="g-card showdown-card winner" style="box-shadow:none; background: #e8f0fe;">
                    <div class="winner-badge">üèÜ Winner</div>
                    <div class="icon-box ib-blue" style="margin: 0 auto 16px; background:white;"><i
                            data-lucide="network"></i></div>
                    <h4 style="color: var(--g-blue);">Hybrid CNN-GRU</h4>
                    <p style="color: var(--text-sec); font-size: 14px; margin-top: 8px;">Extracts spatial logic
                        lighting-fast with CNN layers, funnels it gracefully into a GRU memory bank.</p>
                </div>
            </div>
        </section>

        <!-- 6. Architecture Walkthrough -->
        <section class="g-card reveal" id="architecture">
            <div class="section-header">
                <h2>5. Architecture Walkthrough</h2>
                <p>The code that makes it happen.</p>
            </div>
            <div class="code-header">traffic_prediction.py &middot; Class: HybridTrafficModel</div>
            <pre class="hljs-container"><code class="language-python">class HybridTrafficModel(nn.Module):
    def __init__(self, num_input_features, num_output_sensors, seq_length):
        super(HybridTrafficModel, self).__init__()
        
        # 1. Spatial Trend Extraction
        self.conv1 = nn.Conv1d(num_input_features, out_channels=64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm1d(64)
        
        # 2. Temporal Dynamics
        self.gru1 = nn.GRU(input_size=64, hidden_size=128, batch_first=True)
        self.gru2 = nn.GRU(input_size=128, hidden_size=64, batch_first=True)
        self.bn2 = nn.BatchNorm1d(64)
        self.dropout = nn.Dropout(0.2)
        
        # 3. Prediction Head
        self.fc1 = nn.Linear(64, 64)
        self.fc_out = nn.Linear(64, num_output_sensors)
        self.relu = nn.ReLU()

    def forward(self, x):
        # Permute for Conv1d: (Batch, Features, Seq_Length)
        x = x.permute(0, 2, 1)
        x = self.relu(self.bn1(self.conv1(x)))
        
        # Permute for GRU: (Batch, Seq_Length, Features)
        x = x.permute(0, 2, 1)
        x, _ = self.gru1(x)
        x = self.dropout(x)
        x, _ = self.gru2(x)
        
        # Many-to-One: Take last time step
        x = self.dropout(self.bn2(x[:, -1, :]))
        
        # Dense layers
        x = self.relu(self.fc1(x))
        return self.fc_out(x)</code></pre>
        </section>

        <!-- 7. Results -->
        <section class="g-card reveal" id="results">
            <div class="section-header">
                <h2>6. Training & Results</h2>
                <p>The outcome from processing over 52,000 steps.</p>
            </div>

            <div class="grid-3" style="margin-bottom: 24px;">
                <div style="text-align:center;">
                    <h1 style="color: var(--g-blue); font-size: 36px; margin-bottom: 4px;">0.633</h1>
                    <p style="color: var(--text-sec); font-size: 14px; font-weight: 500;">R¬≤ Score</p>
                </div>
                <div style="text-align:center;">
                    <h1 style="color: var(--g-red); font-size: 36px; margin-bottom: 4px;">2.348</h1>
                    <p style="color: var(--text-sec); font-size: 14px; font-weight: 500;">Mean Abs Error</p>
                </div>
                <div style="text-align:center;">
                    <h1 style="color: var(--g-yellow); font-size: 36px; margin-bottom: 4px;">4.214</h1>
                    <p style="color: var(--text-sec); font-size: 14px; font-weight: 500;">RMSE</p>
                </div>
            </div>

            <img src="traffic_analysis.png" alt="Training Visuals"
                style="width:100%; border-radius: 8px; border: 1px solid var(--border-color);">
        </section>

    </main>

    <footer>
        <p>Built with precision & passion by <strong>Shyngys Narseyit</strong>. ¬© 2026</p>
        <p style="margin-top: 8px; font-size: 12px;">Styled with Google Material Design 3 Guidelines</p>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            // Init Icons
            lucide.createIcons();
            // Init syntax highlighter
            hljs.highlightAll();

            // Intersectional Observer for Scroll Reveals
            const revealElements = document.querySelectorAll('.reveal');
            const revealObserver = new IntersectionObserver((entries, observer) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('active');
                        observer.unobserve(entry.target);
                    }
                });
            }, { threshold: 0.1, rootMargin: "0px 0px -50px 0px" });

            revealElements.forEach(el => revealObserver.observe(el));
        });
    </script>
</body>

</html>